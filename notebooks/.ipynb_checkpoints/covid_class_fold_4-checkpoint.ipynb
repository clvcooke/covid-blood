{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import tensorflow.keras as keras\n",
    "import shutil\n",
    "from pandas import read_excel\n",
    "import random\n",
    "from sklearn import model_selection\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_INDEX = 4\n",
    "cutoff = 800000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patients = glob.glob('/hddraid5/data/colin/covid-data/COVID Research Images/**/[0-9]*/', recursive=True)\n",
    "patient_dates = {}\n",
    "for patient in all_patients:\n",
    "    patient = patient[:-1]\n",
    "    patient_id = os.path.basename(patient)\n",
    "    date = os.path.basename(os.path.dirname(patient))\n",
    "    patient_dates[patient_id] = date\n",
    "base_path = '/hddraid5/data/colin/covid-data/'\n",
    "label_files = glob.glob(os.path.join(base_path, '*.xlsx'))\n",
    "orders = []\n",
    "test_results = []\n",
    "for label_file in label_files:\n",
    "    table = read_excel(label_file)\n",
    "    table_orders = list(table['Order #'])\n",
    "    table_test_results = list(table['Covid Test result'])\n",
    "    orders = orders + table_orders\n",
    "    test_results = test_results + table_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets compile a DB\n",
    "positive_images = {}\n",
    "negative_images = {}\n",
    "for order, test_result in zip(orders, test_results):\n",
    "    try:\n",
    "        label = 'positive' in test_result.lower()\n",
    "        np.int(order)\n",
    "    except (TypeError, AttributeError):\n",
    "        continue\n",
    "    all_image_paths = glob.glob(os.path.join(base_path, 'COVID Research Images','**', str(order),'**', '*.jpg'), recursive=True)\n",
    "    image_paths = [image_path for image_path in all_image_paths if (os.path.getsize(image_path) < cutoff and os.path.getsize(image_path) > 100)]\n",
    "    if label:\n",
    "        positive_images[str(order)] = image_paths\n",
    "    else:\n",
    "        negative_images[str(order)] = image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_orders = list(positive_images.keys())\n",
    "negative_orders = list(negative_images.keys())\n",
    "positive_orders = [order for order in positive_orders if order in patient_dates]\n",
    "negative_orders = [order for order in negative_orders if order in patient_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold(data, random_state=0, split_index=0, folds=6):\n",
    "    folder = model_selection.KFold(n_splits=folds, shuffle=True, random_state=random_state)\n",
    "    splits = folder.split(X=negative_orders)\n",
    "    for i, split in enumerate(splits):\n",
    "        if i == split_index:\n",
    "            break\n",
    "    data = np.array(data)\n",
    "    return data[split[0]], data[split[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_orders(orders, image_paths, label=0):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    all_orders = []\n",
    "    all_files = []\n",
    "    for order in tqdm(orders):\n",
    "        images = []\n",
    "        labels = []\n",
    "        orders = []\n",
    "        files = []\n",
    "        for image_path in image_paths[order]:\n",
    "            image = cv.imread(image_path)\n",
    "            image = cv.resize(image, (224, 224))\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "            orders.append(order)\n",
    "            files.append(os.path.basename(image_path))\n",
    "        all_images += images\n",
    "        all_labels += labels\n",
    "        all_orders += orders\n",
    "        all_files  += files\n",
    "    return all_images, all_labels, all_orders, all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positive_orders, val_positive_orders = get_fold(positive_orders, split_index=SPLIT_INDEX)\n",
    "train_negative_orders, val_negative_orders = get_fold(negative_orders, split_index=SPLIT_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/colin/anaconda3/envs/covid/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04765a894da7497597fd8776dc6591ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=64.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aabb5025ae24d73a48f21ffc9f2e751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=64.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc9a274f7fd4d279df761ec85f6d402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07de8cbbb3b14dc4a2b812f4d6320617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_pos_images, train_pos_labels, train_pos_orders, train_pos_files = load_orders(train_positive_orders, positive_images, 1)\n",
    "train_neg_images, train_neg_labels, train_neg_orders, train_neg_files = load_orders(train_negative_orders, negative_images, 0)\n",
    "train_images = train_pos_images + train_neg_images\n",
    "train_labels = train_pos_labels + train_neg_labels\n",
    "train_orders = train_pos_orders + train_neg_orders\n",
    "train_files = train_pos_files + train_neg_files\n",
    "\n",
    "\n",
    "val_pos_images, val_pos_labels, val_pos_orders, val_pos_files = load_orders(val_positive_orders, positive_images, 1)\n",
    "val_neg_images, val_neg_labels, val_neg_orders, val_neg_files = load_orders(val_negative_orders, negative_images, 0)\n",
    "val_images = val_pos_images + val_neg_images\n",
    "val_labels = val_pos_labels + val_neg_labels\n",
    "val_orders = val_pos_orders + val_neg_orders\n",
    "val_files = val_pos_files + val_neg_files\n",
    "\n",
    "train_images = (np.array(train_images) / 255).astype(np.float32)\n",
    "val_images = (np.array(val_images) / 255).astype(np.float32)\n",
    "train_labels = np.array(train_labels)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape=(224,224,3), model_name='mobilenet_v2'):\n",
    "    if model_name == 'mobilenet_v2':\n",
    "        base_model = keras.applications.mobilenet_v2.MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    elif model_name == 'densenet':\n",
    "        base_model = keras.applications.densenet.DenseNet121(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    elif model_name == 'xception':\n",
    "        base_model = keras.applications.xception.Xception(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    base_model.trainable = False\n",
    "    x = base_model(inputs, training=False) # IMPORTANT\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dense(256, activation='relu')(x) # just train this and following layer\n",
    "    outputs = keras.layers.Dense(2, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_proc = keras.preprocessing.image.ImageDataGenerator(rotation_range=45, horizontal_flip=True, vertical_flip=True, shear_range=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(train_images.reshape(-1, 3), axis=0)\n",
    "stds = np.std(train_images.reshape(-1, 3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = (train_images - means) / stds\n",
    "train_y = keras.utils.to_categorical(train_labels)\n",
    "val_x = (val_images - means) / stds\n",
    "val_y = keras.utils.to_categorical(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chance = np.sum(train_labels)/len(train_labels)\n",
    "val_chance = np.sum(val_labels)/len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train chance  0.5545964869922134\n",
      "Val chance  0.5675389902194026\n"
     ]
    }
   ],
   "source": [
    "print(\"Train chance \", train_chance)\n",
    "print(\"Val chance \", val_chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1035.4375 steps, validate on 3783 samples\n",
      "Epoch 1/25\n",
      "1036/1035 [==============================] - 188s 181ms/step - loss: 0.5565 - accuracy: 0.7133 - val_loss: 0.6827 - val_accuracy: 0.6252\n",
      "Epoch 2/25\n",
      "1036/1035 [==============================] - 192s 185ms/step - loss: 0.4880 - accuracy: 0.7598 - val_loss: 0.6491 - val_accuracy: 0.6564\n",
      "Epoch 3/25\n",
      "1036/1035 [==============================] - 197s 190ms/step - loss: 0.4654 - accuracy: 0.7764 - val_loss: 0.6563 - val_accuracy: 0.6595\n",
      "Epoch 4/25\n",
      "1036/1035 [==============================] - 201s 194ms/step - loss: 0.4459 - accuracy: 0.7877 - val_loss: 0.6580 - val_accuracy: 0.6677\n",
      "Epoch 5/25\n",
      "1036/1035 [==============================] - 183s 177ms/step - loss: 0.4270 - accuracy: 0.8004 - val_loss: 0.6369 - val_accuracy: 0.6815\n",
      "Epoch 6/25\n",
      "1036/1035 [==============================] - 192s 185ms/step - loss: 0.4162 - accuracy: 0.8047 - val_loss: 0.6282 - val_accuracy: 0.6897\n",
      "Epoch 7/25\n",
      "1036/1035 [==============================] - 202s 195ms/step - loss: 0.4028 - accuracy: 0.8142 - val_loss: 0.5845 - val_accuracy: 0.7145\n",
      "Epoch 8/25\n",
      "1036/1035 [==============================] - 184s 178ms/step - loss: 0.3965 - accuracy: 0.8170 - val_loss: 0.6451 - val_accuracy: 0.6942\n",
      "Epoch 9/25\n",
      "1036/1035 [==============================] - 181s 175ms/step - loss: 0.3928 - accuracy: 0.8186 - val_loss: 0.6394 - val_accuracy: 0.6923\n",
      "Epoch 10/25\n",
      "1036/1035 [==============================] - 197s 191ms/step - loss: 0.3818 - accuracy: 0.8282 - val_loss: 0.5993 - val_accuracy: 0.7103\n",
      "Epoch 11/25\n",
      "1036/1035 [==============================] - 191s 185ms/step - loss: 0.3772 - accuracy: 0.8285 - val_loss: 0.6402 - val_accuracy: 0.6883\n",
      "Epoch 12/25\n",
      "1036/1035 [==============================] - 203s 196ms/step - loss: 0.3728 - accuracy: 0.8281 - val_loss: 0.6632 - val_accuracy: 0.6844\n",
      "Epoch 13/25\n",
      "1036/1035 [==============================] - 189s 182ms/step - loss: 0.3719 - accuracy: 0.8325 - val_loss: 0.6564 - val_accuracy: 0.6870\n",
      "Epoch 14/25\n",
      "1036/1035 [==============================] - 189s 183ms/step - loss: 0.3682 - accuracy: 0.8332 - val_loss: 0.6272 - val_accuracy: 0.7079\n",
      "Epoch 15/25\n",
      "1036/1035 [==============================] - 188s 182ms/step - loss: 0.3599 - accuracy: 0.8387 - val_loss: 0.5913 - val_accuracy: 0.7172\n",
      "Epoch 16/25\n",
      "1036/1035 [==============================] - 203s 196ms/step - loss: 0.3613 - accuracy: 0.8375 - val_loss: 0.6407 - val_accuracy: 0.6981\n",
      "Epoch 17/25\n",
      "1036/1035 [==============================] - 185s 179ms/step - loss: 0.3593 - accuracy: 0.8352 - val_loss: 0.6491 - val_accuracy: 0.6907\n",
      "Epoch 18/25\n",
      "1036/1035 [==============================] - 199s 192ms/step - loss: 0.3456 - accuracy: 0.8448 - val_loss: 0.6870 - val_accuracy: 0.6823\n",
      "Epoch 19/25\n",
      "1036/1035 [==============================] - 182s 175ms/step - loss: 0.3491 - accuracy: 0.8451 - val_loss: 0.6321 - val_accuracy: 0.7016\n",
      "Epoch 20/25\n",
      "1036/1035 [==============================] - 200s 193ms/step - loss: 0.3408 - accuracy: 0.8468 - val_loss: 0.6686 - val_accuracy: 0.6846\n",
      "Epoch 21/25\n",
      "1036/1035 [==============================] - 183s 177ms/step - loss: 0.3401 - accuracy: 0.8479 - val_loss: 0.5571 - val_accuracy: 0.7383\n",
      "Epoch 22/25\n",
      "1036/1035 [==============================] - 196s 189ms/step - loss: 0.3418 - accuracy: 0.8451 - val_loss: 0.6858 - val_accuracy: 0.6770\n",
      "Epoch 23/25\n",
      "1000/1035 [===========================>..] - ETA: 6s - loss: 0.3372 - accuracy: 0.8504"
     ]
    }
   ],
   "source": [
    "model = get_model(model_name='densenet')\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "callbacks = keras.callbacks.ModelCheckpoint(f'densenet_covid_fold_{SPLIT_INDEX}.hdf5')\n",
    "batch_size = 16\n",
    "model.fit(image_proc.flow(train_x, train_y, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(train_x) / batch_size, epochs=25, validation_data=(val_x, val_y), shuffle=False, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = keras.models.load_model(f'densenet_covid_fold_{SPLIT_INDEX}.hdf5')\n",
    "labels = saved_model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "}\n",
    "\n",
    "for order, label, gt, file in zip(val_orders, labels, val_labels, val_files):\n",
    "    if order in results:\n",
    "        results[order]['labels'].append(float(label[1]))\n",
    "        results[order]['files'].append(file)\n",
    "    else:\n",
    "        if gt == 1:\n",
    "            test = True\n",
    "        else:\n",
    "            test = False\n",
    "        results[order] = {\n",
    "            'test_result': test,\n",
    "            'labels': [float(label[1])],\n",
    "            'files': [file]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'val_results_v1_fold_{SPLIT_INDEX}.json', 'w') as fp:\n",
    "    json.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
