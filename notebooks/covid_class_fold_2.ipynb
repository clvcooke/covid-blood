{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import tensorflow.keras as keras\n",
    "import shutil\n",
    "from pandas import read_excel\n",
    "import random\n",
    "from sklearn import model_selection\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_INDEX = 2\n",
    "cutoff = 800000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patients = glob.glob('/hddraid5/data/colin/covid-data/COVID Research Images/**/[0-9]*/', recursive=True)\n",
    "patient_dates = {}\n",
    "for patient in all_patients:\n",
    "    patient = patient[:-1]\n",
    "    patient_id = os.path.basename(patient)\n",
    "    date = os.path.basename(os.path.dirname(patient))\n",
    "    patient_dates[patient_id] = date\n",
    "base_path = '/hddraid5/data/colin/covid-data/'\n",
    "label_files = glob.glob(os.path.join(base_path, '*.xlsx'))\n",
    "orders = []\n",
    "test_results = []\n",
    "for label_file in label_files:\n",
    "    table = read_excel(label_file)\n",
    "    table_orders = list(table['Order #'])\n",
    "    table_test_results = list(table['Covid Test result'])\n",
    "    orders = orders + table_orders\n",
    "    test_results = test_results + table_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets compile a DB\n",
    "positive_images = {}\n",
    "negative_images = {}\n",
    "for order, test_result in zip(orders, test_results):\n",
    "    try:\n",
    "        label = 'positive' in test_result.lower()\n",
    "        np.int(order)\n",
    "    except (TypeError, AttributeError):\n",
    "        continue\n",
    "    all_image_paths = glob.glob(os.path.join(base_path, 'COVID Research Images','**', str(order),'**', '*.jpg'), recursive=True)\n",
    "    image_paths = [image_path for image_path in all_image_paths if (os.path.getsize(image_path) < cutoff and os.path.getsize(image_path) > 100)]\n",
    "    if label:\n",
    "        positive_images[str(order)] = image_paths\n",
    "    else:\n",
    "        negative_images[str(order)] = image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_orders = list(positive_images.keys())\n",
    "negative_orders = list(negative_images.keys())\n",
    "positive_orders = [order for order in positive_orders if order in patient_dates]\n",
    "negative_orders = [order for order in negative_orders if order in patient_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold(data, random_state=0, split_index=0, folds=6):\n",
    "    folder = model_selection.KFold(n_splits=folds, shuffle=True, random_state=random_state)\n",
    "    splits = folder.split(X=data)\n",
    "    for i, split in enumerate(splits):\n",
    "        if i == split_index:\n",
    "            break\n",
    "    data = np.array(data)\n",
    "    return data[split[0]], data[split[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_orders(orders, image_paths, label=0):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    all_orders = []\n",
    "    all_files = []\n",
    "    for order in tqdm(orders):\n",
    "        images = []\n",
    "        labels = []\n",
    "        orders = []\n",
    "        files = []\n",
    "        for image_path in image_paths[order]:\n",
    "            image = cv.imread(image_path)\n",
    "            image = cv.resize(image, (224, 224))\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "            orders.append(order)\n",
    "            files.append(os.path.basename(image_path))\n",
    "        all_images += images\n",
    "        all_labels += labels\n",
    "        all_orders += orders\n",
    "        all_files  += files\n",
    "    return all_images, all_labels, all_orders, all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positive_orders, val_positive_orders = get_fold(positive_orders, split_index=SPLIT_INDEX)\n",
    "train_negative_orders, val_negative_orders = get_fold(negative_orders, split_index=SPLIT_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/colin/anaconda3/envs/covid/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687add81dc164540929ad3c7e5211258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=64.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7993525a29a4d37901de7c09676ac0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=64.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe5f64056d848aba902fad4cf41aa9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4500e21d464bfb9eb8a79f48d507f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_pos_images, train_pos_labels, train_pos_orders, train_pos_files = load_orders(train_positive_orders, positive_images, 1)\n",
    "train_neg_images, train_neg_labels, train_neg_orders, train_neg_files = load_orders(train_negative_orders, negative_images, 0)\n",
    "train_images = train_pos_images + train_neg_images\n",
    "train_labels = train_pos_labels + train_neg_labels\n",
    "train_orders = train_pos_orders + train_neg_orders\n",
    "train_files = train_pos_files + train_neg_files\n",
    "\n",
    "\n",
    "val_pos_images, val_pos_labels, val_pos_orders, val_pos_files = load_orders(val_positive_orders, positive_images, 1)\n",
    "val_neg_images, val_neg_labels, val_neg_orders, val_neg_files = load_orders(val_negative_orders, negative_images, 0)\n",
    "val_images = val_pos_images + val_neg_images\n",
    "val_labels = val_pos_labels + val_neg_labels\n",
    "val_orders = val_pos_orders + val_neg_orders\n",
    "val_files = val_pos_files + val_neg_files\n",
    "\n",
    "train_images = (np.array(train_images) / 255).astype(np.float32)\n",
    "val_images = (np.array(val_images) / 255).astype(np.float32)\n",
    "train_labels = np.array(train_labels)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape=(224,224,3), model_name='mobilenet_v2'):\n",
    "    if model_name == 'mobilenet_v2':\n",
    "        base_model = keras.applications.mobilenet_v2.MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    elif model_name == 'densenet':\n",
    "        base_model = keras.applications.densenet.DenseNet121(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    elif model_name == 'xception':\n",
    "        base_model = keras.applications.xception.Xception(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    base_model.trainable = False\n",
    "    x = base_model(inputs, training=False) # IMPORTANT\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dense(256, activation='relu')(x) # just train this and following layer\n",
    "    outputs = keras.layers.Dense(2, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_proc = keras.preprocessing.image.ImageDataGenerator(rotation_range=45, horizontal_flip=True, vertical_flip=True, shear_range=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(train_images.reshape(-1, 3), axis=0)\n",
    "stds = np.std(train_images.reshape(-1, 3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = (train_images - means) / stds\n",
    "train_y = keras.utils.to_categorical(train_labels)\n",
    "val_x = (val_images - means) / stds\n",
    "val_y = keras.utils.to_categorical(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chance = np.sum(train_labels)/len(train_labels)\n",
    "val_chance = np.sum(val_labels)/len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train chance  0.5415581340279422\n",
      "Val chance  0.6324465008675535\n"
     ]
    }
   ],
   "source": [
    "print(\"Train chance \", train_chance)\n",
    "print(\"Val chance \", val_chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1055.75 steps, validate on 3458 samples\n",
      "Epoch 1/25\n",
      "1056/1055 [==============================] - 211s 199ms/step - loss: 0.5787 - accuracy: 0.6958 - val_loss: 0.5748 - val_accuracy: 0.7050\n",
      "Epoch 2/25\n",
      "1056/1055 [==============================] - 201s 191ms/step - loss: 0.5098 - accuracy: 0.7479 - val_loss: 0.5256 - val_accuracy: 0.7458\n",
      "Epoch 3/25\n",
      "1056/1055 [==============================] - 201s 190ms/step - loss: 0.4812 - accuracy: 0.7657 - val_loss: 0.5714 - val_accuracy: 0.7047\n",
      "Epoch 4/25\n",
      "1056/1055 [==============================] - 201s 191ms/step - loss: 0.4640 - accuracy: 0.7749 - val_loss: 0.5397 - val_accuracy: 0.7276\n",
      "Epoch 5/25\n",
      "1056/1055 [==============================] - 202s 192ms/step - loss: 0.4497 - accuracy: 0.7863 - val_loss: 0.5507 - val_accuracy: 0.7192\n",
      "Epoch 6/25\n",
      "1056/1055 [==============================] - 203s 192ms/step - loss: 0.4376 - accuracy: 0.7913 - val_loss: 0.5196 - val_accuracy: 0.7467\n",
      "Epoch 7/25\n",
      "1056/1055 [==============================] - 203s 192ms/step - loss: 0.4233 - accuracy: 0.7993 - val_loss: 0.5374 - val_accuracy: 0.7423\n",
      "Epoch 8/25\n",
      "1056/1055 [==============================] - 203s 192ms/step - loss: 0.4091 - accuracy: 0.8124 - val_loss: 0.5291 - val_accuracy: 0.7409\n",
      "Epoch 9/25\n",
      "1056/1055 [==============================] - 199s 189ms/step - loss: 0.4094 - accuracy: 0.8080 - val_loss: 0.5019 - val_accuracy: 0.7678\n",
      "Epoch 10/25\n",
      "1056/1055 [==============================] - 202s 191ms/step - loss: 0.4025 - accuracy: 0.8093 - val_loss: 0.5395 - val_accuracy: 0.7507\n",
      "Epoch 11/25\n",
      "1056/1055 [==============================] - 204s 193ms/step - loss: 0.3920 - accuracy: 0.8181 - val_loss: 0.5271 - val_accuracy: 0.7464\n",
      "Epoch 12/25\n",
      "1056/1055 [==============================] - 202s 191ms/step - loss: 0.3891 - accuracy: 0.8234 - val_loss: 0.4973 - val_accuracy: 0.7640\n",
      "Epoch 13/25\n",
      "1056/1055 [==============================] - 199s 189ms/step - loss: 0.3850 - accuracy: 0.8209 - val_loss: 0.5359 - val_accuracy: 0.7383\n",
      "Epoch 14/25\n",
      "1056/1055 [==============================] - 203s 193ms/step - loss: 0.3750 - accuracy: 0.8293 - val_loss: 0.5336 - val_accuracy: 0.7484\n",
      "Epoch 15/25\n",
      "1056/1055 [==============================] - 201s 190ms/step - loss: 0.3817 - accuracy: 0.8259 - val_loss: 0.5030 - val_accuracy: 0.7548\n",
      "Epoch 16/25\n",
      "1056/1055 [==============================] - 201s 191ms/step - loss: 0.3731 - accuracy: 0.8260 - val_loss: 0.5189 - val_accuracy: 0.7490\n",
      "Epoch 17/25\n",
      "1056/1055 [==============================] - 201s 190ms/step - loss: 0.3638 - accuracy: 0.8328 - val_loss: 0.5303 - val_accuracy: 0.7536\n",
      "Epoch 18/25\n",
      "1056/1055 [==============================] - 198s 187ms/step - loss: 0.3636 - accuracy: 0.8332 - val_loss: 0.5061 - val_accuracy: 0.7713\n",
      "Epoch 19/25\n",
      "1056/1055 [==============================] - 198s 188ms/step - loss: 0.3586 - accuracy: 0.8393 - val_loss: 0.4992 - val_accuracy: 0.7733\n",
      "Epoch 20/25\n",
      "1056/1055 [==============================] - 200s 189ms/step - loss: 0.3595 - accuracy: 0.8328 - val_loss: 0.4691 - val_accuracy: 0.7814\n",
      "Epoch 21/25\n",
      "1056/1055 [==============================] - 201s 191ms/step - loss: 0.3552 - accuracy: 0.8368 - val_loss: 0.5705 - val_accuracy: 0.7475\n",
      "Epoch 22/25\n",
      "1056/1055 [==============================] - 203s 192ms/step - loss: 0.3493 - accuracy: 0.8434 - val_loss: 0.4950 - val_accuracy: 0.7597\n",
      "Epoch 23/25\n",
      "1056/1055 [==============================] - 201s 190ms/step - loss: 0.3433 - accuracy: 0.8457 - val_loss: 0.5389 - val_accuracy: 0.7516\n",
      "Epoch 24/25\n",
      "1056/1055 [==============================] - 194s 183ms/step - loss: 0.3431 - accuracy: 0.8462 - val_loss: 0.4815 - val_accuracy: 0.7736\n",
      "Epoch 25/25\n",
      "1056/1055 [==============================] - 199s 189ms/step - loss: 0.3399 - accuracy: 0.8489 - val_loss: 0.5217 - val_accuracy: 0.7571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0cb00d5850>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(model_name='densenet')\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "callbacks = keras.callbacks.ModelCheckpoint(f'densenet_covid_fold_{SPLIT_INDEX}.hdf5')\n",
    "batch_size = 16\n",
    "model.fit(image_proc.flow(train_x, train_y, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(train_x) / batch_size, epochs=25, validation_data=(val_x, val_y), shuffle=False, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = keras.models.load_model(f'densenet_covid_fold_{SPLIT_INDEX}.hdf5')\n",
    "labels = saved_model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "}\n",
    "\n",
    "for order, label, gt, file in zip(val_orders, labels, val_labels, val_files):\n",
    "    if order in results:\n",
    "        results[order]['labels'].append(float(label[1]))\n",
    "        results[order]['files'].append(file)\n",
    "    else:\n",
    "        if gt == 1:\n",
    "            test = True\n",
    "        else:\n",
    "            test = False\n",
    "        results[order] = {\n",
    "            'test_result': test,\n",
    "            'labels': [float(label[1])],\n",
    "            'files': [file]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'val_results_v1_fold_{SPLIT_INDEX}.json', 'w') as fp:\n",
    "    json.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
