{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import tensorflow.keras as keras\n",
    "import shutil\n",
    "from pandas import read_excel\n",
    "import random\n",
    "from sklearn import model_selection\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_INDEX = 3\n",
    "cutoff = 800000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patients = glob.glob('/hddraid5/data/colin/covid-data/COVID Research Images/**/[0-9]*/', recursive=True)\n",
    "patient_dates = {}\n",
    "for patient in all_patients:\n",
    "    patient = patient[:-1]\n",
    "    patient_id = os.path.basename(patient)\n",
    "    date = os.path.basename(os.path.dirname(patient))\n",
    "    patient_dates[patient_id] = date\n",
    "base_path = '/hddraid5/data/colin/covid-data/'\n",
    "label_files = glob.glob(os.path.join(base_path, '*.xlsx'))\n",
    "orders = []\n",
    "test_results = []\n",
    "for label_file in label_files:\n",
    "    table = read_excel(label_file)\n",
    "    table_orders = list(table['Order #'])\n",
    "    table_test_results = list(table['Covid Test result'])\n",
    "    orders = orders + table_orders\n",
    "    test_results = test_results + table_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets compile a DB\n",
    "positive_images = {}\n",
    "negative_images = {}\n",
    "for order, test_result in zip(orders, test_results):\n",
    "    try:\n",
    "        label = 'positive' in test_result.lower()\n",
    "        np.int(order)\n",
    "    except (TypeError, AttributeError):\n",
    "        continue\n",
    "    all_image_paths = glob.glob(os.path.join(base_path, 'COVID Research Images','**', str(order),'**', '*.jpg'), recursive=True)\n",
    "    image_paths = [image_path for image_path in all_image_paths if (os.path.getsize(image_path) < cutoff and os.path.getsize(image_path) > 100)]\n",
    "    if label:\n",
    "        positive_images[str(order)] = image_paths\n",
    "    else:\n",
    "        negative_images[str(order)] = image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_orders = list(positive_images.keys())\n",
    "negative_orders = list(negative_images.keys())\n",
    "positive_orders = [order for order in positive_orders if order in patient_dates]\n",
    "negative_orders = [order for order in negative_orders if order in patient_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold(data, random_state=0, split_index=0, folds=6):\n",
    "    folder = model_selection.KFold(n_splits=folds, shuffle=True, random_state=random_state)\n",
    "    splits = folder.split(X=negative_orders)\n",
    "    for i, split in enumerate(splits):\n",
    "        if i == split_index:\n",
    "            break\n",
    "    data = np.array(data)\n",
    "    return data[split[0]], data[split[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_orders(orders, image_paths, label=0):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    all_orders = []\n",
    "    all_files = []\n",
    "    for order in tqdm(orders):\n",
    "        images = []\n",
    "        labels = []\n",
    "        orders = []\n",
    "        files = []\n",
    "        for image_path in image_paths[order]:\n",
    "            image = cv.imread(image_path)\n",
    "            image = cv.resize(image, (224, 224))\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "            orders.append(order)\n",
    "            files.append(os.path.basename(image_path))\n",
    "        all_images += images\n",
    "        all_labels += labels\n",
    "        all_orders += orders\n",
    "        all_files  += files\n",
    "    return all_images, all_labels, all_orders, all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positive_orders, val_positive_orders = get_fold(positive_orders, split_index=SPLIT_INDEX)\n",
    "train_negative_orders, val_negative_orders = get_fold(negative_orders, split_index=SPLIT_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/colin/anaconda3/envs/covid/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981790e1414c4602a138820160c9be0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=64.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdd0597666c44a8b8cb48da3b4412bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=64.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b506c58df346b79bf53c10e19cd5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bee14701e66483b9783e50a6c325651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_pos_images, train_pos_labels, train_pos_orders, train_pos_files = load_orders(train_positive_orders, positive_images, 1)\n",
    "train_neg_images, train_neg_labels, train_neg_orders, train_neg_files = load_orders(train_negative_orders, negative_images, 0)\n",
    "train_images = train_pos_images + train_neg_images\n",
    "train_labels = train_pos_labels + train_neg_labels\n",
    "train_orders = train_pos_orders + train_neg_orders\n",
    "train_files = train_pos_files + train_neg_files\n",
    "\n",
    "\n",
    "val_pos_images, val_pos_labels, val_pos_orders, val_pos_files = load_orders(val_positive_orders, positive_images, 1)\n",
    "val_neg_images, val_neg_labels, val_neg_orders, val_neg_files = load_orders(val_negative_orders, negative_images, 0)\n",
    "val_images = val_pos_images + val_neg_images\n",
    "val_labels = val_pos_labels + val_neg_labels\n",
    "val_orders = val_pos_orders + val_neg_orders\n",
    "val_files = val_pos_files + val_neg_files\n",
    "\n",
    "train_images = (np.array(train_images) / 255).astype(np.float32)\n",
    "val_images = (np.array(val_images) / 255).astype(np.float32)\n",
    "train_labels = np.array(train_labels)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape=(224,224,3), model_name='mobilenet_v2'):\n",
    "    if model_name == 'mobilenet_v2':\n",
    "        base_model = keras.applications.mobilenet_v2.MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    elif model_name == 'densenet':\n",
    "        base_model = keras.applications.densenet.DenseNet121(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    elif model_name == 'xception':\n",
    "        base_model = keras.applications.xception.Xception(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    base_model.trainable = False\n",
    "    x = base_model(inputs, training=False) # IMPORTANT\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dense(256, activation='relu')(x) # just train this and following layer\n",
    "    outputs = keras.layers.Dense(2, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_proc = keras.preprocessing.image.ImageDataGenerator(rotation_range=45, horizontal_flip=True, vertical_flip=True, shear_range=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(train_images.reshape(-1, 3), axis=0)\n",
    "stds = np.std(train_images.reshape(-1, 3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = (train_images - means) / stds\n",
    "train_y = keras.utils.to_categorical(train_labels)\n",
    "val_x = (val_images - means) / stds\n",
    "val_y = keras.utils.to_categorical(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chance = np.sum(train_labels)/len(train_labels)\n",
    "val_chance = np.sum(val_labels)/len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train chance  0.5530324480434906\n",
      "Val chance  0.5830546265328874\n"
     ]
    }
   ],
   "source": [
    "print(\"Train chance \", train_chance)\n",
    "print(\"Val chance \", val_chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1103.6875 steps, validate on 2691 samples\n",
      "Epoch 1/25\n",
      "1104/1103 [==============================] - 216s 196ms/step - loss: 0.5571 - accuracy: 0.7132 - val_loss: 0.5691 - val_accuracy: 0.7038\n",
      "Epoch 2/25\n",
      "1104/1103 [==============================] - 213s 193ms/step - loss: 0.4830 - accuracy: 0.7675 - val_loss: 0.5764 - val_accuracy: 0.7012\n",
      "Epoch 3/25\n",
      "1104/1103 [==============================] - 210s 190ms/step - loss: 0.4519 - accuracy: 0.7857 - val_loss: 0.5894 - val_accuracy: 0.6979\n",
      "Epoch 4/25\n",
      "1104/1103 [==============================] - 211s 191ms/step - loss: 0.4344 - accuracy: 0.7966 - val_loss: 0.6232 - val_accuracy: 0.6931\n",
      "Epoch 5/25\n",
      "1104/1103 [==============================] - 209s 190ms/step - loss: 0.4189 - accuracy: 0.8020 - val_loss: 0.5845 - val_accuracy: 0.7157\n",
      "Epoch 6/25\n",
      "1104/1103 [==============================] - 204s 184ms/step - loss: 0.4087 - accuracy: 0.8077 - val_loss: 0.6240 - val_accuracy: 0.6983\n",
      "Epoch 7/25\n",
      "1104/1103 [==============================] - 210s 190ms/step - loss: 0.3951 - accuracy: 0.8148 - val_loss: 0.5951 - val_accuracy: 0.7049\n",
      "Epoch 8/25\n",
      "1104/1103 [==============================] - 208s 189ms/step - loss: 0.3861 - accuracy: 0.8219 - val_loss: 0.6550 - val_accuracy: 0.6931\n",
      "Epoch 9/25\n",
      "1104/1103 [==============================] - 211s 191ms/step - loss: 0.3814 - accuracy: 0.8226 - val_loss: 0.5619 - val_accuracy: 0.7395\n",
      "Epoch 10/25\n",
      "1104/1103 [==============================] - 210s 191ms/step - loss: 0.3740 - accuracy: 0.8283 - val_loss: 0.6169 - val_accuracy: 0.6983\n",
      "Epoch 11/25\n",
      "1104/1103 [==============================] - 210s 190ms/step - loss: 0.3687 - accuracy: 0.8331 - val_loss: 0.6174 - val_accuracy: 0.7127\n",
      "Epoch 12/25\n",
      "1104/1103 [==============================] - 207s 187ms/step - loss: 0.3594 - accuracy: 0.8367 - val_loss: 0.5982 - val_accuracy: 0.7258\n",
      "Epoch 13/25\n",
      "1104/1103 [==============================] - 210s 190ms/step - loss: 0.3566 - accuracy: 0.8381 - val_loss: 0.7112 - val_accuracy: 0.6808\n",
      "Epoch 14/25\n",
      "1104/1103 [==============================] - 209s 190ms/step - loss: 0.3531 - accuracy: 0.8410 - val_loss: 0.6216 - val_accuracy: 0.7165\n",
      "Epoch 15/25\n",
      "1104/1103 [==============================] - 211s 191ms/step - loss: 0.3462 - accuracy: 0.8443 - val_loss: 0.6285 - val_accuracy: 0.7135\n",
      "Epoch 16/25\n",
      "1104/1103 [==============================] - 210s 190ms/step - loss: 0.3451 - accuracy: 0.8463 - val_loss: 0.6680 - val_accuracy: 0.6916\n",
      "Epoch 17/25\n",
      "1104/1103 [==============================] - 211s 191ms/step - loss: 0.3396 - accuracy: 0.8470 - val_loss: 0.6458 - val_accuracy: 0.7139\n",
      "Epoch 18/25\n",
      "1104/1103 [==============================] - 211s 191ms/step - loss: 0.3333 - accuracy: 0.8485 - val_loss: 0.6464 - val_accuracy: 0.7176\n",
      "Epoch 19/25\n",
      "1104/1103 [==============================] - 210s 190ms/step - loss: 0.3322 - accuracy: 0.8516 - val_loss: 0.6420 - val_accuracy: 0.7213\n",
      "Epoch 20/25\n",
      "1104/1103 [==============================] - 210s 190ms/step - loss: 0.3314 - accuracy: 0.8533 - val_loss: 0.6556 - val_accuracy: 0.7109\n",
      "Epoch 21/25\n",
      "1104/1103 [==============================] - 211s 191ms/step - loss: 0.3298 - accuracy: 0.8514 - val_loss: 0.6725 - val_accuracy: 0.7146\n",
      "Epoch 22/25\n",
      "1104/1103 [==============================] - 211s 191ms/step - loss: 0.3250 - accuracy: 0.8557 - val_loss: 0.6217 - val_accuracy: 0.7120\n",
      "Epoch 23/25\n",
      "1104/1103 [==============================] - 205s 186ms/step - loss: 0.3184 - accuracy: 0.8595 - val_loss: 0.7985 - val_accuracy: 0.6808\n",
      "Epoch 24/25\n",
      "1104/1103 [==============================] - 206s 187ms/step - loss: 0.3176 - accuracy: 0.8618 - val_loss: 0.6854 - val_accuracy: 0.7061\n",
      "Epoch 25/25\n",
      "1104/1103 [==============================] - 203s 184ms/step - loss: 0.3177 - accuracy: 0.8604 - val_loss: 0.7923 - val_accuracy: 0.7005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f48285ad190>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(model_name='densenet')\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "callbacks = keras.callbacks.ModelCheckpoint(f'densenet_covid_fold_{SPLIT_INDEX}.hdf5')\n",
    "batch_size = 16\n",
    "model.fit(image_proc.flow(train_x, train_y, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(train_x) / batch_size, epochs=25, validation_data=(val_x, val_y), shuffle=False, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = keras.models.load_model(f'densenet_covid_fold_{SPLIT_INDEX}.hdf5')\n",
    "labels = saved_model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "}\n",
    "\n",
    "for order, label, gt, file in zip(val_orders, labels, val_labels, val_files):\n",
    "    if order in results:\n",
    "        results[order]['labels'].append(float(label[1]))\n",
    "        results[order]['files'].append(file)\n",
    "    else:\n",
    "        if gt == 1:\n",
    "            test = True\n",
    "        else:\n",
    "            test = False\n",
    "        results[order] = {\n",
    "            'test_result': test,\n",
    "            'labels': [float(label[1])],\n",
    "            'files': [file]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'val_results_v1_fold_{SPLIT_INDEX}.json', 'w') as fp:\n",
    "    json.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
