{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.5.0\n",
      "Torchvision Version:  0.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import PIL\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pandas import read_excel\n",
    "import torch.nn.functional as F\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder('/hddraid5/data/colin/cell_classification/data/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "    \n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft, input_size = initialize_model('densenet', 9, True)\n",
    "model_ft.load_state_dict(torch.load('wbc_dense.pt'))\n",
    "model_ft.eval()\n",
    "cutoff = 800000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 224\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ColorJitter(brightness=0.10, contrast=0.20, saturation=0.20, hue=0.20),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/hddraid5/data/colin/covid-data/'\n",
    "label_files = glob.glob(os.path.join(base_path, '*.xlsx'))\n",
    "orders = []\n",
    "test_results = []\n",
    "for label_file in label_files:\n",
    "    table = read_excel(label_file)\n",
    "    table_orders = list(table['Order #'])\n",
    "    table_test_results = list(table['Covid Test result'])\n",
    "    orders = orders + table_orders\n",
    "    test_results = test_results + table_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets compile a DB\n",
    "all_images = {}\n",
    "for order, test_result in zip(orders, test_results):\n",
    "    try:\n",
    "        label = 'positive' in test_result.lower()\n",
    "        np.int(order)\n",
    "    except (TypeError, AttributeError):\n",
    "        continue\n",
    "    all_image_paths = glob.glob(os.path.join(base_path, 'COVID Research Images','**', str(order), '*.jpg'), recursive=True)\n",
    "    image_paths = [image_path for image_path in all_image_paths if (os.path.getsize(image_path) < cutoff and os.path.getsize(image_path) > 100)]\n",
    "    all_images[str(order)] = image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "all_cell_classes = {}\n",
    "for patient, image_paths in all_images.items():\n",
    "    test_images = [data_transforms(PIL.Image.open(image_path)) for image_path in image_paths]\n",
    "    for i in np.arange(0, len(test_images), batch_size):\n",
    "        tensors = torch.stack(test_images[i:i+batch_size])\n",
    "        class_probs = F.softmax(model_ft(tensors), dim=-1)\n",
    "        cell_classes = torch.argmax(class_probs, dim=-1).tolist()\n",
    "        if i == 0:\n",
    "            all_cell_classes[patient] = cell_classes\n",
    "        else:\n",
    "            all_cell_classes[patient] += cell_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = all_images[patient]\n",
    "images = [PIL.Image.open(ip) for ip in image_paths]\n",
    "cell_indices = all_cell_classes[patient]\n",
    "cell_labels = np.array(cell_types)[cell_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 100\n",
    "print(cell_labels[index])\n",
    "images[index]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images[patient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = {}\n",
    "for patient in all_images.keys():\n",
    "    patient_data[patient] = {\n",
    "        \n",
    "    }\n",
    "    try:\n",
    "        for image_path, cell_type in zip(all_images[patient], all_cell_classes[patient]):\n",
    "            patient_data[patient][os.path.basename(image_path)] = cell_labels[cell_type]\n",
    "    except KeyError:\n",
    "        pass\n",
    "with open('wbc_classes_v1_jitter.json', 'w') as fp:\n",
    "    json.dump(patient_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wbc_classes_v1.json\", 'wb') as fp:\n",
    "    \n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    writer.writerow(['Patient ID', 'filename', 'Cell Type'])\n",
    "    for patient in all_images.keys():\n",
    "        try:\n",
    "            for image_path, cell_type in zip(all_images[patient], all_cell_classes[patient]):\n",
    "                writer.writerow([patient, os.path.basename(image_path), cell_labels[cell_type]])\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wbc_classes_v1.json\", 'wb') as fp:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    writer.writerow(['Patient ID', 'filename', 'Cell Type'])\n",
    "    for patient in all_images.keys():\n",
    "        try:\n",
    "            for image_path, cell_type in zip(all_images[patient], all_cell_classes[patient]):\n",
    "                writer.writerow([patient, os.path.basename(image_path), cell_labels[cell_type]])\n",
    "        except KeyError:\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
