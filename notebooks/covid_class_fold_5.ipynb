{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import tensorflow.keras as keras\n",
    "import shutil\n",
    "from pandas import read_excel\n",
    "import random\n",
    "from sklearn import model_selection\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_INDEX = 3\n",
    "cutoff = 800000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patients = glob.glob('/hddraid5/data/colin/covid-data/COVID Research Images/**/[0-9]*/', recursive=True)\n",
    "patient_dates = {}\n",
    "for patient in all_patients:\n",
    "    patient = patient[:-1]\n",
    "    patient_id = os.path.basename(patient)\n",
    "    date = os.path.basename(os.path.dirname(patient))\n",
    "    patient_dates[patient_id] = date\n",
    "base_path = '/hddraid5/data/colin/covid-data/'\n",
    "label_files = glob.glob(os.path.join(base_path, '*.xlsx'))\n",
    "orders = []\n",
    "test_results = []\n",
    "for label_file in label_files:\n",
    "    table = read_excel(label_file)\n",
    "    table_orders = list(table['Order #'])\n",
    "    table_test_results = list(table['Covid Test result'])\n",
    "    orders = orders + table_orders\n",
    "    test_results = test_results + table_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets compile a DB\n",
    "positive_images = {}\n",
    "negative_images = {}\n",
    "for order, test_result in zip(orders, test_results):\n",
    "    try:\n",
    "        label = 'positive' in test_result.lower()\n",
    "        np.int(order)\n",
    "    except (TypeError, AttributeError):\n",
    "        continue\n",
    "    all_image_paths = glob.glob(os.path.join(base_path, 'COVID Research Images','**', str(order), '*.jpg'), recursive=True)\n",
    "    image_paths = [image_path for image_path in all_image_paths if (os.path.getsize(image_path) < cutoff and os.path.getsize(image_path) > 100)]\n",
    "    if label:\n",
    "        positive_images[str(order)] = image_paths\n",
    "    else:\n",
    "        negative_images[str(order)] = image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_orders = list(positive_images.keys())\n",
    "negative_orders = list(negative_images.keys())\n",
    "positive_orders = [order for order in positive_orders if order in patient_dates]\n",
    "negative_orders = [order for order in negative_orders if order in patient_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold(data, random_state=0, split_index=0, folds=6):\n",
    "    folder = model_selection.KFold(n_splits=folds, shuffle=True, random_state=random_state)\n",
    "    splits = folder.split(X=negative_orders)\n",
    "    for i, split in enumerate(splits):\n",
    "        if i == split_index:\n",
    "            break\n",
    "    data = np.array(data)\n",
    "    return data[split[0]], data[split[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_orders(orders, image_paths, label=0):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    all_orders = []\n",
    "    all_files = []\n",
    "    for order in tqdm(orders):\n",
    "        images = []\n",
    "        labels = []\n",
    "        orders = []\n",
    "        files = []\n",
    "        for image_path in image_paths[order]:\n",
    "            image = cv.imread(image_path)\n",
    "            image = cv.resize(image, (224, 224))\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "            orders.append(order)\n",
    "            files.append(os.path.basename(image_path))\n",
    "        all_images += images\n",
    "        all_labels += labels\n",
    "        all_orders += orders\n",
    "        all_files  += files\n",
    "    return all_images, all_labels, all_orders, all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positive_orders, val_positive_orders = get_fold(positive_orders, split_index=SPLIT_INDEX)\n",
    "train_negative_orders, val_negative_orders = get_fold(negative_orders, split_index=SPLIT_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/colin/anaconda3/envs/covid/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1851ad9191a4d78bcae4641733c3561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=64.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a9d81413a541039c87ffe648d98077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=64.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5375bf607ba456e8edb92bf807730ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73a9091933a4187bb868be833eafc77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_pos_images, train_pos_labels, train_pos_orders, train_pos_files = load_orders(train_positive_orders, positive_images, 1)\n",
    "train_neg_images, train_neg_labels, train_neg_orders, train_neg_files = load_orders(train_negative_orders, negative_images, 0)\n",
    "train_images = train_pos_images + train_neg_images\n",
    "train_labels = train_pos_labels + train_neg_labels\n",
    "train_orders = train_pos_orders + train_neg_orders\n",
    "train_files = train_pos_files + train_neg_files\n",
    "\n",
    "\n",
    "val_pos_images, val_pos_labels, val_pos_orders, val_pos_files = load_orders(val_positive_orders, positive_images, 1)\n",
    "val_neg_images, val_neg_labels, val_neg_orders, val_neg_files = load_orders(val_negative_orders, negative_images, 0)\n",
    "val_images = val_pos_images + val_neg_images\n",
    "val_labels = val_pos_labels + val_neg_labels\n",
    "val_orders = val_pos_orders + val_neg_orders\n",
    "val_files = val_pos_files + val_neg_files\n",
    "\n",
    "train_images = (np.array(train_images) / 255).astype(np.float32)\n",
    "val_images = (np.array(val_images) / 255).astype(np.float32)\n",
    "train_labels = np.array(train_labels)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape=(224,224,3), model_name='mobilenet_v2'):\n",
    "    if model_name == 'mobilenet_v2':\n",
    "        base_model = keras.applications.mobilenet_v2.MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    elif model_name == 'densenet':\n",
    "        base_model = keras.applications.densenet.DenseNet121(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    elif model_name == 'xception':\n",
    "        base_model = keras.applications.xception.Xception(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    base_model.trainable = False\n",
    "    x = base_model(inputs, training=False) # IMPORTANT\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dense(256, activation='relu')(x) # just train this and following layer\n",
    "    outputs = keras.layers.Dense(2, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_proc = keras.preprocessing.image.ImageDataGenerator(rotation_range=45, horizontal_flip=True, vertical_flip=True, shear_range=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(train_images.reshape(-1, 3), axis=0)\n",
    "stds = np.std(train_images.reshape(-1, 3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = (train_images - means) / stds\n",
    "train_y = keras.utils.to_categorical(train_labels)\n",
    "val_x = (val_images - means) / stds\n",
    "val_y = keras.utils.to_categorical(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chance = np.sum(train_labels)/len(train_labels)\n",
    "val_chance = np.sum(val_labels)/len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train chance  0.5685178716963558\n",
      "Val chance  0.588963963963964\n"
     ]
    }
   ],
   "source": [
    "print(\"Train chance \", train_chance)\n",
    "print(\"Val chance \", val_chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1073.625 steps, validate on 2664 samples\n",
      "Epoch 1/25\n",
      "1074/1073 [==============================] - 194s 180ms/step - loss: 0.5698 - accuracy: 0.7036 - val_loss: 0.6212 - val_accuracy: 0.6659\n",
      "Epoch 2/25\n",
      "1074/1073 [==============================] - 190s 177ms/step - loss: 0.4932 - accuracy: 0.7602 - val_loss: 0.6466 - val_accuracy: 0.6644\n",
      "Epoch 3/25\n",
      "1074/1073 [==============================] - 205s 191ms/step - loss: 0.4648 - accuracy: 0.7795 - val_loss: 0.6259 - val_accuracy: 0.6783\n",
      "Epoch 4/25\n",
      "1074/1073 [==============================] - 204s 190ms/step - loss: 0.4444 - accuracy: 0.7896 - val_loss: 0.6198 - val_accuracy: 0.6899\n",
      "Epoch 5/25\n",
      "1074/1073 [==============================] - 186s 173ms/step - loss: 0.4266 - accuracy: 0.8011 - val_loss: 0.6271 - val_accuracy: 0.6892\n",
      "Epoch 6/25\n",
      "1074/1073 [==============================] - 205s 191ms/step - loss: 0.4122 - accuracy: 0.8042 - val_loss: 0.6058 - val_accuracy: 0.7057\n",
      "Epoch 7/25\n",
      "1074/1073 [==============================] - 192s 178ms/step - loss: 0.4039 - accuracy: 0.8144 - val_loss: 0.6297 - val_accuracy: 0.6877\n",
      "Epoch 8/25\n",
      "1074/1073 [==============================] - 204s 190ms/step - loss: 0.3911 - accuracy: 0.8201 - val_loss: 0.5779 - val_accuracy: 0.7196\n",
      "Epoch 9/25\n",
      "1074/1073 [==============================] - 192s 179ms/step - loss: 0.3869 - accuracy: 0.8248 - val_loss: 0.5847 - val_accuracy: 0.7140\n",
      "Epoch 10/25\n",
      "1074/1073 [==============================] - 202s 188ms/step - loss: 0.3802 - accuracy: 0.8273 - val_loss: 0.5812 - val_accuracy: 0.7158\n",
      "Epoch 11/25\n",
      "1074/1073 [==============================] - 200s 186ms/step - loss: 0.3753 - accuracy: 0.8295 - val_loss: 0.5602 - val_accuracy: 0.7294\n",
      "Epoch 12/25\n",
      "1074/1073 [==============================] - 204s 190ms/step - loss: 0.3666 - accuracy: 0.8324 - val_loss: 0.6212 - val_accuracy: 0.6869\n",
      "Epoch 13/25\n",
      "1074/1073 [==============================] - 183s 170ms/step - loss: 0.3628 - accuracy: 0.8384 - val_loss: 0.5615 - val_accuracy: 0.7290\n",
      "Epoch 14/25\n",
      "1074/1073 [==============================] - 200s 187ms/step - loss: 0.3549 - accuracy: 0.8401 - val_loss: 0.5811 - val_accuracy: 0.7181\n",
      "Epoch 15/25\n",
      "1074/1073 [==============================] - 183s 171ms/step - loss: 0.3579 - accuracy: 0.8398 - val_loss: 0.5406 - val_accuracy: 0.7399\n",
      "Epoch 16/25\n",
      "1074/1073 [==============================] - 197s 184ms/step - loss: 0.3470 - accuracy: 0.8458 - val_loss: 0.5675 - val_accuracy: 0.7309\n",
      "Epoch 17/25\n",
      "1074/1073 [==============================] - 192s 179ms/step - loss: 0.3437 - accuracy: 0.8458 - val_loss: 0.5514 - val_accuracy: 0.7429\n",
      "Epoch 18/25\n",
      "1074/1073 [==============================] - 184s 171ms/step - loss: 0.3326 - accuracy: 0.8496 - val_loss: 0.6090 - val_accuracy: 0.7275\n",
      "Epoch 19/25\n",
      "1074/1073 [==============================] - 188s 175ms/step - loss: 0.3368 - accuracy: 0.8510 - val_loss: 0.5770 - val_accuracy: 0.7384\n",
      "Epoch 20/25\n",
      "1074/1073 [==============================] - 199s 185ms/step - loss: 0.3329 - accuracy: 0.8513 - val_loss: 0.5896 - val_accuracy: 0.7312\n",
      "Epoch 21/25\n",
      "1074/1073 [==============================] - 199s 186ms/step - loss: 0.3284 - accuracy: 0.8552 - val_loss: 0.5903 - val_accuracy: 0.7309\n",
      "Epoch 22/25\n",
      "1074/1073 [==============================] - 185s 173ms/step - loss: 0.3294 - accuracy: 0.8497 - val_loss: 0.6248 - val_accuracy: 0.7188\n",
      "Epoch 23/25\n",
      "1074/1073 [==============================] - 193s 180ms/step - loss: 0.3234 - accuracy: 0.8573 - val_loss: 0.6231 - val_accuracy: 0.7241\n",
      "Epoch 24/25\n",
      "1074/1073 [==============================] - 195s 182ms/step - loss: 0.3238 - accuracy: 0.8521 - val_loss: 0.6116 - val_accuracy: 0.7297\n",
      "Epoch 25/25\n",
      "1074/1073 [==============================] - 184s 171ms/step - loss: 0.3227 - accuracy: 0.8542 - val_loss: 0.6449 - val_accuracy: 0.7181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa22813b0d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(model_name='densenet')\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "callbacks = keras.callbacks.ModelCheckpoint(f'densenet_covid_fold_{SPLIT_INDEX}.hdf5')\n",
    "batch_size = 16\n",
    "model.fit(image_proc.flow(train_x, train_y, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(train_x) / batch_size, epochs=25, validation_data=(val_x, val_y), shuffle=False, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = keras.models.load_model(f'densenet_covid_fold_{SPLIT_INDEX}.hdf5')\n",
    "labels = saved_model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "}\n",
    "\n",
    "for order, label, gt, file in zip(val_orders, labels, val_labels, val_files):\n",
    "    if order in results:\n",
    "        results[order]['labels'].append(float(label[1]))\n",
    "        results[order]['files'].append(file)\n",
    "    else:\n",
    "        if gt == 1:\n",
    "            test = True\n",
    "        else:\n",
    "            test = False\n",
    "        results[order] = {\n",
    "            'test_result': test,\n",
    "            'labels': [float(label[1])],\n",
    "            'files': [file]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'val_results_v1_fold_{SPLIT_INDEX}_rev.json', 'w') as fp:\n",
    "    json.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT_INDEX"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
